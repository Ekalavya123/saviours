{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "import math\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "SAMPLE_RATE = 1000\n",
    "TRACK_DURATION = 179 # measured in seconds  var_2\n",
    "num_segments=179\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "JSON_PATH_TRAIN = \"data_10.json\" \n",
    "JSON_PATH_TEST=\"test_10.json\"\n",
    "file_names=[]\n",
    "audio_names=[]\n",
    "n=3\n",
    "DATASET_PATH =\"/Users/91837/projects/Saviours/train_audios(1)\"  #path of directary which contain training audios\n",
    "t_audio=\"/Users/91837/projects/Saviours/test_audios(1)/test_audio.wav\" #path of test_file\n",
    "song=\"/Users/91837/projects/Saviours/test_audios(1)\"#path of directary which contain test audios\n",
    "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=500,hop_length=250,num_segments=num_segments): #***\n",
    "    # dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "     \n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "    # loop through all genre sub-folder\n",
    "    for (dirpath,dirnames,filenames) in os.walk(dataset_path):\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"/\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "            # process all audio files in genre sub-dir\n",
    "            j=0\n",
    "            for f in filenames:\n",
    "                file_names.append(f)\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                audio_names.append(file_path)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                # process all segments of audio file\n",
    "                for d in range(num_segments):\n",
    "                    # calculate start and finish sample for current segment\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "                    # extract mfcc\n",
    "                    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    mfcc = mfcc.T\n",
    "                    # store only mfcc feature with expected number of vectors\n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment+1:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(j)\n",
    "                        #print(\"{}, segment:{}\".format(file_path, d+1))\n",
    "                j=j+1\n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp,indent=4)\n",
    "if __name__ == \"__main__\":\n",
    "    save_mfcc(DATASET_PATH, JSON_PATH_TRAIN, num_segments=179)\n",
    "\n",
    "DATA_PATH = JSON_PATH_TRAIN \n",
    "def load_data(data_path):\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    #print(X[0])\n",
    "    print(\"Data succesfully loaded!\")\n",
    "\n",
    "    return  X, y\n",
    "\n",
    "\n",
    "def plot_history(history):  #graphs train and test \n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    # create accuracy sublpot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "\n",
    "    # create error sublpot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ### 3) training the model using keras ###\n",
    "    \n",
    "    # load data\n",
    "    X, y = load_data(DATA_PATH)\n",
    "\n",
    "    # create train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # build network topology\n",
    "    #multi layer model\n",
    "    model = keras.Sequential([\n",
    "\n",
    "        # input layer\n",
    "        keras.layers.Flatten(input_shape=(X.shape[1], X.shape[2])),\n",
    "\n",
    "        # 1st dense layer\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "        # 2nd dense layer\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "\n",
    "        # 3rd dense layer\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "\n",
    "        # output layer\n",
    "        keras.layers.Dense(n, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # compile model\n",
    "    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # train model\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=100)\n",
    "\n",
    "    # plot accuracy and error as a function of the epochs\n",
    "    plot_history(history)\n",
    "    \n",
    "    \n",
    "    #num_segments=89    #adjust no of segments of given audio      var_3\n",
    "    #SAMPLE_RATE = 1000\n",
    "    #TRACK_DURATION = 89 # measured in seconds                      var_4\n",
    "    #SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "    #samples_per_segment = int(SAMPLES_PER_TRACK /TRACK_DURATION)\n",
    "    print(file_names)\n",
    "    save_mfcc(song,JSON_PATH_TEST,num_segments=num_segments)\n",
    "    X,y=load_data(JSON_PATH_TEST)\n",
    "    prid_values=[]\n",
    "    for d in range(num_segments):\n",
    "        seg_array=X[d]\n",
    "        mfcc=np.reshape(seg_array,(1,5,13))\n",
    "        pridiction=model.predict(mfcc) \n",
    "        pridiction=pridiction.tolist()\n",
    "        max_val=max(pridiction[0])\n",
    "        out_put=pridiction[0].index(max_val)\n",
    "        prid_values.append(out_put)\n",
    "    print(\"pridicted values of segments : \\n {} \\n\".format(prid_values))\n",
    "    \n",
    "    init_seg_prid=prid_values[0]\n",
    "    audio_sep_n=[]\n",
    "    audio_sep_t=[]\n",
    "    j=0\n",
    "    for i in prid_values:\n",
    "        if i!=init_seg_prid and j<=(len(prid_values)-3):\n",
    "            if prid_values[j]==prid_values[j+1] and prid_values[j]==prid_values[j+2]: \n",
    "                audio_sep_t.append(j)\n",
    "                audio_sep_n.append(init_seg_prid)\n",
    "                init_seg_prid=prid_values[j]\n",
    "        j=j+1\n",
    "    audio_sep_t.append(len(prid_values)-1)\n",
    "    audio_sep_n.append(prid_values[audio_sep_t[len(audio_sep_t)-2]])\n",
    "    print(\"indices of persons in the given audio are: {} \\n\".format(audio_sep_n))\n",
    "    print(\"start timings of respective persons are : {} \\n\".format(audio_sep_t)) \n",
    "    \n",
    "    ### 6) decoding the audios using speech recogniser and pydub ###\n",
    "    T1=0\n",
    "    l=1\n",
    "    for i in range(len(audio_sep_n)):\n",
    "        T2=(audio_sep_t[i])*1000\n",
    "        if ((T2-T1)/1000)>=10:\n",
    "            second_of_silence = AudioSegment.silent(2000) \n",
    "            ekaAudio = AudioSegment.from_wav(t_audio)\n",
    "            ekaAudio = ekaAudio[T1:T2]\n",
    "            ekaAudio=second_of_silence+ekaAudio+second_of_silence\n",
    "            ekaAudio.export('ekaSong{}.wav'.format(i),format=\"wav\") #Exports to a wav file in the current path.\n",
    "            k=0\n",
    "            chunk_audio= AudioSegment.from_wav('ekaSong{}.wav'.format(i))\n",
    "            print(\"\\n\")\n",
    "            print(\"{}) from {}sec to {}sec is spoken by: {} \\n\".format(l,T1/1000,T2/1000,file_names[audio_sep_n[i]]))\n",
    "            print(\"{}:\".format(file_names[audio_sep_n[i]]))\n",
    "            T1=T2\n",
    "            # split track where silence is 0.5 seconds \n",
    "            # or more and get chunks\n",
    "            chunks = split_on_silence(chunk_audio,\n",
    "                # must be silent for at least 0.5 seconds\n",
    "                # or 500 ms. adjust this value based on user\n",
    "                # requirement. if the speaker stays silent for \n",
    "                # longer, increase this value. else, decrease it.\n",
    "                min_silence_len = 500,\n",
    "\n",
    "                # consider it silent if quieter than -16 dBFS\n",
    "                # adjust this per requirement\n",
    "                silence_thresh = -50\n",
    "            )\n",
    "            # process each chunk\n",
    "            l=l+1\n",
    "            for chunk in chunks:\n",
    "\n",
    "                # Create 0.5 seconds silence chunk\n",
    "                chunk_silent = AudioSegment.silent(duration = 10)\n",
    "\n",
    "                # add 0.5 sec silence to beginning and \n",
    "                # end of audio chunk. This is done so that\n",
    "                # it doesn't seem abruptly sliced.\n",
    "                audio_chunk = chunk_silent + chunk + chunk_silent\n",
    "\n",
    "                # export audio chunk and save it in \n",
    "                # the current directory.\n",
    "                #print(\"saving chunk{0}.wav\".format(k))\n",
    "                audio_chunk.export(\"./chunk{0}.wav\".format(k), bitrate ='192k', format =\"wav\")\n",
    "\n",
    "                # the name of the newly created chunk\n",
    "                filename = 'chunk'+str(k)+'.wav'\n",
    "\n",
    "                #print(\"Processing chunk \"+str(k))\n",
    "\n",
    "                # get the name of the newly created chunk\n",
    "                # in the AUDIO_FILE variable for later use.\n",
    "                file = filename\n",
    "\n",
    "                # create a speech recognition object\n",
    "                r = sr.Recognizer()\n",
    "\n",
    "                # recognize the chunk\n",
    "                with sr.AudioFile(file) as source:\n",
    "                    # remove this if it is not working\n",
    "                    # correctly.\n",
    "                    r.adjust_for_ambient_noise(source)\n",
    "                    audio_listened = r.listen(source)\n",
    "\n",
    "                try:\n",
    "                    # try converting it to text\n",
    "                    rec = r.recognize_google(audio_listened)\n",
    "                    # write the output to the file.\n",
    "                    print(rec,end=\" \")\n",
    "\n",
    "                # catch any errors.\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"Could not understand audio\",end=\" \")\n",
    "\n",
    "                except sr.RequestError as e:\n",
    "                    print(\"Could not request results. check your internet connection\")\n",
    "\n",
    "                k=k+1\n",
    "            if ((T2-T1)/1000)>=10:\n",
    "                fh.write(\"\\n\")\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315dedcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
